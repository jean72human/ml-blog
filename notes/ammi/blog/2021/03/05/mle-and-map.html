<!DOCTYPE html>
<html lang="en"><head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="twitter:card" content="summary_large_image" /><!-- Begin Jekyll SEO tag v2.6.1 -->
<title>AMMI notes - MLE and MAP | Gbetondji Dovonon</title>
<meta name="generator" content="Jekyll v4.1.1" />
<meta property="og:title" content="AMMI notes - MLE and MAP" />
<meta name="author" content="Gbetondji Dovonon" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="maximum likelihood estimation and maximum a posteriori estimation" />
<meta property="og:description" content="maximum likelihood estimation and maximum a posteriori estimation" />
<link rel="canonical" href="https://jean72human.github.io/ml-blog/notes/ammi/blog/2021/03/05/mle-and-map.html" />
<meta property="og:url" content="https://jean72human.github.io/ml-blog/notes/ammi/blog/2021/03/05/mle-and-map.html" />
<meta property="og:site_name" content="Gbetondji Dovonon" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2021-03-05T00:00:00-06:00" />
<script type="application/ld+json">
{"author":{"@type":"Person","name":"Gbetondji Dovonon"},"headline":"AMMI notes - MLE and MAP","description":"maximum likelihood estimation and maximum a posteriori estimation","datePublished":"2021-03-05T00:00:00-06:00","dateModified":"2021-03-05T00:00:00-06:00","@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"https://jean72human.github.io/ml-blog/notes/ammi/blog/2021/03/05/mle-and-map.html"},"url":"https://jean72human.github.io/ml-blog/notes/ammi/blog/2021/03/05/mle-and-map.html","@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->
<link rel="stylesheet" href="/ml-blog/assets/css/style.css"><link type="application/atom+xml" rel="alternate" href="https://jean72human.github.io/ml-blog/feed.xml" title="Gbetondji Dovonon" /><link rel="shortcut icon" type="image/x-icon" href="/ml-blog/images/favicon.ico"><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/Primer/15.2.0/primer.css" integrity="sha512-xTz2ys4coGAOz8vuV1NcQBkgVmKhsSEtjbqyMJbBHRplFuvKIUo6xhLHpAyPt9mfR6twHJgn9OgVLuqOvjeBhg==" crossorigin="anonymous" />
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.14.0/css/all.min.css" integrity="sha512-1PKOgIY59xJ8Co8+NE6FZ+LOAZKjy+KY8iq0G4B3CyeY6wYHN3yt9PW0XpSriVlkMXe40PTKnXrLnZ9+fkDaog==" crossorigin="anonymous" />
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.12.0/katex.min.css" integrity="sha512-h7nl+xz8wgDlNM4NqKEM4F1NkIRS17M9+uJwIGwuo8vGqIl4BhuCKdxjWEINm+xyrUjNCnK5dCrhM0sj+wTIXw==" crossorigin="anonymous" />
    <script src="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.12.0/katex.min.js" integrity="sha512-/CMIhXiDA3m2c9kzRyd97MTb3MC6OVnx4TElQ7fkkoRghwDf6gi41gaT1PwF270W6+J60uTmwgeRpNpJdRV6sg==" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.12.0/contrib/auto-render.min.js" integrity="sha512-Do7uJAaHZm5OLrIv/yN4w0iG1dbu01kzdMNnFfu/mAqgUk6Nniv2JYHcwH+cNwjqgLcqcuBBk+JRvprLVI8azg==" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js" integrity="sha512-0doc9hKxR3PYwso42RD1p5ySZpzzuDiOwMrdCEh2WdJZCjcmFKc/wEnL+z8fBQrnHoiNWbo+3fiGkOYXBdQp4A==" crossorigin="anonymous"></script>
    <script>
    document.addEventListener("DOMContentLoaded", function() {
        renderMathInElement( document.body, {
        delimiters: [
            {left: "$$", right: "$$", display: true},
            {left: "[%", right: "%]", display: true},
            {left: "$", right: "$", display: false}
        ]}
        );
    });
    </script>


<script>
function wrap_img(fn) {
    if (document.attachEvent ? document.readyState === "complete" : document.readyState !== "loading") {
        var elements = document.querySelectorAll(".post img");
        Array.prototype.forEach.call(elements, function(el, i) {
            if (el.getAttribute("title") && (el.className != "emoji")) {
                const caption = document.createElement('figcaption');
                var node = document.createTextNode(el.getAttribute("title"));
                caption.appendChild(node);
                const wrapper = document.createElement('figure');
                wrapper.className = 'image';
                el.parentNode.insertBefore(wrapper, el);
                el.parentNode.removeChild(el);
                wrapper.appendChild(el);
                wrapper.appendChild(caption);
            }
        });
    } else { document.addEventListener('DOMContentLoaded', fn); }
}
window.onload = wrap_img;
</script>

<script>
    document.addEventListener("DOMContentLoaded", function(){
    // add link icon to anchor tags
    var elem = document.querySelectorAll(".anchor-link")
    elem.forEach(e => (e.innerHTML = '<i class="fas fa-link fa-xs"></i>'));
    });
</script>
</head>
<body><header class="site-header">

  <div class="wrapper"><a class="site-title" rel="author" href="/ml-blog/">Gbetondji Dovonon</a><nav class="site-nav">
        <input type="checkbox" id="nav-trigger" class="nav-trigger" />
        <label for="nav-trigger">
          <span class="menu-icon">
            <svg viewBox="0 0 18 15" width="18px" height="15px">
              <path d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.032C17.335,0,18,0.665,18,1.484L18,1.484z M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.032C17.335,6.031,18,6.696,18,7.516L18,7.516z M18,13.516C18,14.335,17.335,15,16.516,15H1.484 C0.665,15,0,14.335,0,13.516l0,0c0-0.82,0.665-1.483,1.484-1.483h15.032C17.335,12.031,18,12.695,18,13.516L18,13.516z"/>
            </svg>
          </span>
        </label>

        <div class="trigger"><a class="page-link" href="/ml-blog/blog/">Blog</a><a class="page-link" href="/ml-blog/research/">Research</a><a class="page-link" href="/ml-blog/search/">Search</a><a class="page-link" href="/ml-blog/categories/">Tags</a></div>
      </nav></div>
</header>
<main class="page-content" aria-label="Content">
      <div class="wrapper">
        <article class="post h-entry" itemscope itemtype="http://schema.org/BlogPosting">

  <header class="post-header">
    <h1 class="post-title p-name" itemprop="name headline">AMMI notes - MLE and MAP</h1><p class="page-description">maximum likelihood estimation and maximum a posteriori estimation</p><p class="post-meta post-meta-title"><time class="dt-published" datetime="2021-03-05T00:00:00-06:00" itemprop="datePublished">
        Mar 5, 2021
      </time>• 
          <span itemprop="author" itemscope itemtype="http://schema.org/Person">
            <span class="p-author h-card" itemprop="name">Gbetondji Dovonon</span></span>
       • <span class="read-time" title="Estimated read time">
    
    
      2 min read
    
</span></p>

    
      <p class="category-tags"><i class="fas fa-tags category-tags-icon"></i></i> 
      
        <a class="category-tags-link" href="/ml-blog/categories/#notes">notes</a>
        &nbsp;
      
        <a class="category-tags-link" href="/ml-blog/categories/#ammi">ammi</a>
        &nbsp;
      
        <a class="category-tags-link" href="/ml-blog/categories/#blog">blog</a>
        
      
      </p>
    

    
      
        <div class="pb-5 d-flex flex-wrap flex-justify-end">
          <div class="px-2">

    <a href="https://github.com/jean72human/ml-blog/tree/master/_notebooks/2021-03-05-mle-and-map.ipynb" role="button" target="_blank">
<img class="notebook-badge-image" src="/ml-blog/assets/badges/github.svg" alt="View On GitHub">
    </a>
</div>

          <div class="px-2">
    <a href="https://mybinder.org/v2/gh/jean72human/ml-blog/master?filepath=_notebooks%2F2021-03-05-mle-and-map.ipynb" target="_blank">
        <img class="notebook-badge-image" src="/ml-blog/assets/badges/binder.svg" alt="Open In Binder"/>
    </a>
</div>

          <div class="px-2">
    <a href="https://colab.research.google.com/github/jean72human/ml-blog/blob/master/_notebooks/2021-03-05-mle-and-map.ipynb" target="_blank">
        <img class="notebook-badge-image" src="/ml-blog/assets/badges/colab.svg" alt="Open In Colab"/>
    </a>
</div>
        </div>
      </header>

  <div class="post-content e-content" itemprop="articleBody">
    <ul class="section-nav">
<li class="toc-entry toc-h2"><a href="#Maximum-Likelihood-Estimation">Maximum Likelihood Estimation </a></li>
<li class="toc-entry toc-h2"><a href="#Maximum-A-Posteriori">Maximum A Posteriori </a></li>
</ul><!--
#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: _notebooks/2021-03-05-mle-and-map.ipynb
-->

<div class="container" id="notebook-container">
        
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Linear regression works by finding $\underset{\theta}{argmin} \|{X\theta - Y}\|_2^2$. \
The interpretations for the metric we are minimizing are diverse. It can be interpreted as the sum of the euclidian distances between the predictions and actual values. It can also be obtained by maximum likelihood estimation (MLE).</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Maximum-Likelihood-Estimation">
<a class="anchor" href="#Maximum-Likelihood-Estimation" aria-hidden="true"><span class="octicon octicon-link"></span></a>Maximum Likelihood Estimation<a class="anchor-link" href="#Maximum-Likelihood-Estimation"> </a>
</h2>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>In MLE we are interested in finding the value of theta that maximizes the likelihood of the data as expressed by $p(Y|X\theta)$</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Let's consider every data point to be of the form $y_i = x_i \theta + \epsilon$ where $\epsilon$ follows a normal distribution $\mathcal{N}(0,\,\sigma^{2})$ and $y_i$ will follow a distribution $\mathcal{N}(x_i \theta,\,\sigma^{2})$</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Our goal is now to find $\underset{\theta}{argmax}\ p(Y|X,\theta)$</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Because we assume that the data points are independently sampled we can write $p(Y|X,\theta) = \displaystyle\prod_{i=1}^{n} P(y_i|x_i,\theta) $</p>
<p>Then because we assume the data points are identically distributed, in this case with a distribution $\mathcal{N}(x_i \theta,\,\sigma^{2})$, we can write $\displaystyle\prod_{i=1}^{n} P(y_i|x_i,\theta) = \displaystyle\prod_{i=1}^{n} \frac{1}{\sqrt{2 \pi \sigma^2}}exp(-\frac{(y_i - x_i \theta)^2}{2 \sigma^2} $</p>
<p>Lastly, because the $\log$ function is a strictly increasing function, maximizing the likelihood $p(Y|X,\theta)$ is the same as maximizing the log likelihood $\log p(Y|X,\theta)$.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Using that let's develop the expression of the likelihood.
$$
\begin{aligned}
p(Y|X,\theta) &amp; = \displaystyle\prod_{i=1}^{n} P(y_i|x_i,\theta) 
\\
&amp; = \displaystyle\prod_{i=1}^{n} \frac{1}{\sqrt{2 \pi \sigma^2}}exp(-\frac{(y_i - x_i \theta)^2}{2 \sigma^2} )
\\
\log p(Y|X,\theta) &amp; = \displaystyle\sum_{i=1}^{n} \log ( \frac{1}{\sqrt{2 \pi \sigma^2}}exp(-\frac{(y_i - x_i \theta)^2}{2 \sigma^2} ))
\\
&amp; = \displaystyle\sum_{i=1}^{n} \log \frac{1}{\sqrt{2 \pi \sigma^2}} - \displaystyle\sum_{i=1}^{n} \frac{(y_i - x_i \theta)^2}{2 \sigma^2}  
\\
&amp; = n \log 1 - n \log \sqrt{2 \pi \sigma^2} - \frac{1}{2 \sigma^2} \displaystyle\sum_{i=1}^{n} (y_i - x_i \theta)^2 
\\
&amp; = n \log 1 - n \log \sqrt{2 \pi \sigma^2} - \frac{1}{2 \sigma^2} \|{Y - X\theta }\|_2^2
\end{aligned}
$$</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>From that we can see that fincing the value of $\theta$ that maximizes the likelihood is the same as finding the $\theta$ that minimizes $\|{Y - X\theta }\|_2^2$</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>The closed form solution is $\theta^{MLE} = (X^T X)^{-1}X^T Y$</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Maximum-A-Posteriori">
<a class="anchor" href="#Maximum-A-Posteriori" aria-hidden="true"><span class="octicon octicon-link"></span></a>Maximum A Posteriori<a class="anchor-link" href="#Maximum-A-Posteriori"> </a>
</h2>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>In maximum a posteriori estimation (MAP estimation) we consider $\theta$ aa random variable that also follow a normal distribution $\mathcal{N}(0,\,b^{2})$</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>We want to maximize $P(\theta|X,Y)$</p>
<p>Using Baye's theorem we have 
$$
\begin{aligned}
P(\theta|X,Y) &amp; = \frac{P(Y|X,\theta)p(\theta)}{P(Y|X)}
\\
\ log P(\theta|X,Y) &amp; = \log P(Y|X,\theta) + \log p(\theta) - \log P(Y|X)
\\
&amp; = n \log 1 - n \log \sqrt{2 \pi \sigma^2} - \frac{1}{2 \sigma^2} \|{Y - X\theta }\|_2^2 + n \log 1 - n \log \sqrt{2 \pi b^2} - \frac{1}{2 b^2} \|{\theta }\|_2^2 - \log P(Y|X)
\\
&amp; = - (\frac{1}{2 \sigma^2} \|{Y - X\theta }\|_2^2 + \frac{1}{2 b^2} \|{\theta }\|_2^2 ) + c
\end{aligned}
$$</p>
<p>Here $c$ is a constant that groups all the terms that do not depend on $\theta$.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>From this we can see the cost function for ridge regression $\|{Y - X\theta }\|_2^2 + \lambda \|{\theta }\|_2^2$</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Ridge regression can be very useful because of its regularizing effect, and the fact that its closed from solution $\theta^{MAP} = (X^T X + \lambda I_d)^{-1}X^T Y$ always exists. Also, there is a very useful equality for ridge regression that is discusses <a href="https://jean72human.github.io/ml-blog/notes/ammi/blog/2021/02/20/ridge-equality.html">here</a>.</p>

</div>
</div>
</div>
</div>



  </div><!-- from https://github.com/utterance/utterances -->
<script src="https://utteranc.es/client.js"
        repo="jean72human/ml-blog"
        issue-term="title"
        label="blogpost-comment"
        theme="github-light"
        crossorigin="anonymous"
        async>
</script><a class="u-url" href="/ml-blog/notes/ammi/blog/2021/03/05/mle-and-map.html" hidden></a>
</article>
      </div>
    </main><footer class="site-footer h-card">
  <data class="u-url" href="/ml-blog/"></data>

  <div class="wrapper">

    <div class="footer-col-wrapper">
      <div class="footer-col">
        <p class="feed-subscribe">
          <a href="/ml-blog/feed.xml">
            <svg class="svg-icon orange">
              <use xlink:href="/ml-blog/assets/minima-social-icons.svg#rss"></use>
            </svg><span>Subscribe</span>
          </a>
        </p>
      </div>
      <div class="footer-col">
        <p>Aspiring machine learning researcher</p>
      </div>
    </div>

    <div class="social-links"><ul class="social-media-list"><li><a rel="me" href="https://github.com/jean72human" title="jean72human"><svg class="svg-icon grey"><use xlink:href="/ml-blog/assets/minima-social-icons.svg#github"></use></svg></a></li><li><a rel="me" href="https://twitter.com/jean72human" title="jean72human"><svg class="svg-icon grey"><use xlink:href="/ml-blog/assets/minima-social-icons.svg#twitter"></use></svg></a></li></ul>
</div>

  </div>

</footer>
</body>

</html>
